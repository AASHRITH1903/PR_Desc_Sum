{
  "elastic/elasticsearch_37945": {
    "id": "elastic/elasticsearch_37945",
    "body": "Adding release highlights for ES .",
    "cms": [
      "'add es release highlights'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'",
      "'Update docs/reference/release-notes/highlights-6.6.0.asciidoc\\n\\nCo-Authored-By: pcsanwald <paul.sanwald@elastic.co>'"
    ],
    "commits": {
      "'6d643fd6cf38dbbf7a0a201c87901a299b5f20e9'": {
        "cm": "add es release highlights",
        "comments": ""
      },
      "'0f82c284d002eb8efe8dab60f37891266850ef6d'": {
        "cm": "",
        "comments": ""
      },
      "'aa36ad0f8f1ec8b2f34a1eb9dc5fcf4aa9c7c50d'": {
        "cm": "",
        "comments": ""
      },
      "'a728268833bb6a0ba637ccf73d63726c5329ede0'": {
        "cm": "",
        "comments": ""
      },
      "'7ba43435eb7fab49970f3691d01513d31e44db07'": {
        "cm": "",
        "comments": ""
      },
      "'c69b4a799674c091d8cb5acf460a6427ccf158b1'": {
        "cm": "",
        "comments": ""
      },
      "'589e66d4d1cbc900fe3eab61d0b93cc8e2f61a8d'": { "cm": "", "comments": "" }
    }
  },
  "elastic/elasticsearch_37821": {
    "id": "elastic/elasticsearch_37821",
    "body": "Handling LLRC when * * live node size < 0 * *",
    "cms": [
      "'Fix for #37739'",
      "'Adding Test Case'",
      "'Merge remote-tracking branch 'upstream/master''"
    ],
    "commits": {
      "'5c4ffc8a8cd880bfeefc8590f06e539c3ab1ff45'": {
        "cm": "",
        "comments": ""
      },
      "'b5625fd2bb786829266ae11ccf241fd2281c63ac'": {
        "cm": "Adding Test Case",
        "comments": "case when fewer nodeTuple than blacklist , wont result in any IllegalCapacityException"
      },
      "'ac497ff204e5240cdc8a961335cb0ac5edb7b2cc'": {
        "cm": "Merge remote-tracking branch 'upstream/master '",
        "comments": "some test projects do n't have a main source set conventions are not honored when the tasks are disabled Creates an index using the Create Index API . Asynchronously creates an index using the Create Index API . A request to create an index . Constructs a new request to create an index with the specified name . The name of the index to create . The settings to create the index with . The settings to create the index with . The settings to create the index with . The settings to create the index with ( either json or yaml format ) Allows to set the settings using a json builder . The settings to create the index with ( either json/yaml/properties format ) Adds mapping that will be added when the index gets created . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the number of shard copies that should be active for index creation to return . Index creation will only wait up until the timeout value for the number of shard copies to be active before returning . Create index Create index with mappings , aliases and settings As Alias # equals only looks at name , we check the equality of the other Alias parameters here . Randomizes the index name , the aliases , mappings and settings associated with the index . When present , the mappings make no mention of types . Create a random server request , and copy its contents into the HLRC request . Because client requests only accept typeless mappings , we must swap out the mapping definition for one that does not contain types . Creates a random mapping , with no mention of types . reserve \\'null\\ ' for bwc . package private for tests validate the join on the joining node , will throw a failure if it fails the validation NodeToolCli does not extend LoggingAwareCommand , because LoggingAwareCommand performs logging initialization after LoggingAwareCommand instance is constructed . It 's too late for us , because before UnsafeBootstrapMasterCommand is added to the list of subcommands log4j2 initialization will happen , because it has static reference to Logger class . Even if we avoid making a static reference to Logger class , there is no nice way to avoid declaring UNSAFE_BOOTSTRAP , which depends on ClusterService , which in turn has static Logger . Returns null if the provided factory and his parents are compatible with this aggregator or the instance of the parent 's factory that is incompatible with the composite aggregation . different GeoPoints could map to the same or different hashing cells . The encoder to use to convert a geopoint 's ( lon , lat , precision ) into a long-encoded bucket key for aggregating . Aggregates data expressed as longs ( for efficiency 's sake ) but formats results as aggregation-specific strings . private impl that stores a bucket ord . This allows for computing the aggregations lazily . this is done because the aggregator may be rebuilt from cache ( non OrdinalBucket ) , or it may be rebuilding from a new calculation , and therefore copying bucketOrd . This method is used to return a re-usable instance of the bucket when building the aggregation . All geo-grid hash-encoding in a grid are of the same precision and held internally as a single long for efficiency 's sake . Read from a stream . package protected for testing Read from a stream . Returns the total hit count that should be tracked or null if the value is unset . Defaults to null . Returns true if this collector has early terminated . No node available for cluster Performs cluster bootstrap when node with id bootstrapNodeId is started . Any node of the batch could be selected as bootstrap target . client ( ) also starts the node build settings using same path.data as original but with node.data=false and node.master=false test that we can create data=false and master=false with no meta information test that we can create data=false env with only meta information . Also create shard data for following asserts assert that we get the stricter message on meta-data when both conditions fail build settings using same path.data as original but with node.master=false test that we can create master=false env regardless of data . test that we can create data=true , master=true env . Also remove state dir to leave only shard data for following asserts assert that we fail on shard data even without the metadata dir . ignore , this is an expected exception intentionally empty intentionally empty always track total hits accurately"
      }
    }
  },
  "elastic/elasticsearch_37797": {
    "id": "elastic/elasticsearch_37797",
    "body": "We start using this class more often . Let 's make it a top-level class .",
    "cms": [
      "'Make ChannelActionListener a top-level class\\n\\nWe start using this class more often. This commit makes it a top-level class.'",
      "'static logger'",
      "'Merge branch 'master' into channel-listener'"
    ],
    "commits": {
      "'c631cc6cb750a0434fddee123fba343c715a44ff'": {
        "cm": "Make ChannelActionListener a top-level class We start using this class more often . This commit makes it a top-level class .",
        "comments": ""
      },
      "'a0afac5c9586d02ada5f1e515f899871acdfdb05'": {
        "cm": "static logger",
        "comments": ""
      },
      "'ef92abb3e8a764ddf2d1ea0bbe4f307733834dd3'": {
        "cm": "Merge branch 'master ' into channel-listener",
        "comments": "some test projects do n't have a main source set conventions are not honored when the tasks are disabled Creates an index using the Create Index API . Asynchronously creates an index using the Create Index API . Enable a native realm or built-in user synchronously . Constructs a new request to create an index with the specified name . The name of the index to create . The settings to create the index with . The settings to create the index with . The settings to create the index with . The settings to create the index with ( either json or yaml format ) Allows to set the settings using a json builder . The settings to create the index with ( either json/yaml/properties format ) Adds mapping that will be added when the index gets created . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the definition should * not * be nested under a type name . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the settings and mappings as a single source . Note that the mapping definition should * not * be nested under a type name . Sets the number of shard copies that should be active for index creation to return . Index creation will only wait up until the timeout value for the number of shard copies to be active before returning . Create index Create index with mappings , aliases and settings This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation 0 system roles plus the three we created As Alias # equals only looks at name , we check the equality of the other Alias parameters here . Randomizes the index name , the aliases , mappings and settings associated with the index . When present , the mappings make no mention of types . Create a random server request , and copy its contents into the HLRC request . Because client requests only accept typeless mappings , we must swap out the mapping definition for one that does not contain types . Creates a random mapping , with no mention of types . reserve \\'null\\ ' for bwc . The node-level ` discovery.zen.minimum_master_nodes ` setting on the master node that published this cluster state , for use in rolling upgrades from 6.x to 7.x . Once all the 6.x master-eligible nodes have left the cluster , the 7.x nodes use this value to determine how many master-eligible nodes must be discovered before the cluster can be bootstrapped . Note that this method returns the node-level value of this setting , and ignores any cluster-level override that was set via the API . Callers are expected to combine this value with any value set in the cluster-level settings . no Zen1 nodes found , but the last-known master was a Zen1 node , so this is a rolling upgrade NodeToolCli does not extend LoggingAwareCommand , because LoggingAwareCommand performs logging initialization after LoggingAwareCommand instance is constructed . It 's too late for us , because before UnsafeBootstrapMasterCommand is added to the list of subcommands log4j2 initialization will happen , because it has static reference to Logger class . Even if we avoid making a static reference to Logger class , there is no nice way to avoid declaring UNSAFE_BOOTSTRAP , which depends on ClusterService , which in turn has static Logger . Returns null if the provided factory and his parents are compatible with this aggregator or the instance of the parent 's factory that is incompatible with the composite aggregation . different GeoPoints could map to the same or different hashing cells . The encoder to use to convert a geopoint 's ( lon , lat , precision ) into a long-encoded bucket key for aggregating . Aggregates data expressed as longs ( for efficiency 's sake ) but formats results as aggregation-specific strings . private impl that stores a bucket ord . This allows for computing the aggregations lazily . this is done because the aggregator may be rebuilt from cache ( non OrdinalBucket ) , or it may be rebuilding from a new calculation , and therefore copying bucketOrd . This method is used to return a re-usable instance of the bucket when building the aggregation . All geo-grid hash-encoding in a grid are of the same precision and held internally as a single long for efficiency 's sake . Read from a stream . package protected for testing Read from a stream . Returns the total hit count that should be tracked or null if the value is unset . Defaults to null . Returns true if this collector has early terminated . Any node of the batch could be selected as bootstrap target . client ( ) also starts the node build settings using same path.data as original but with node.data=false and node.master=false test that we can create data=false and master=false with no meta information test that we can create data=false env with only meta information . Also create shard data for following asserts assert that we get the stricter message on meta-data when both conditions fail build settings using same path.data as original but with node.master=false test that we can create master=false env regardless of data . test that we can create data=true , master=true env . Also remove state dir to leave only shard data for following asserts assert that we fail on shard data even without the metadata dir ."
      }
    }
  },
  "elastic/elasticsearch_37772": {
    "id": "elastic/elasticsearch_37772",
    "body": "Some of our newer endpoints and indices were missing from the tests .",
    "cms": [
      "'[ML] Fix gaps in reserved roles tests\\n\\nSome of our newer endpoints and indices were missing from\\nthe tests.'",
      "'Merge branch 'master' into fix_gaps_in_roles_tests'"
    ],
    "commits": {
      "'ba46f4125150b915bfbc0e5e0f8a6ecb967b456e'": {
        "cm": "[ ML ] Fix gaps in reserved roles tests Some of our newer endpoints and indices were missing from the tests .",
        "comments": ""
      },
      "'f8198e6cc04f567d770dd06d8d6f319e2fe46ec1'": {
        "cm": "Merge branch 'master ' into fix_gaps_in_roles_tests",
        "comments": "some test projects do n't have a main source set conventions are not honored when the tasks are disabled we need to specify the exact version of build-tools because gradle automatically adds its plugin portal which appears to mirror jcenter , opening us up to pulling a \\'later\\ ' version of build-tools Retrieves the field mappings on an index or indices using the Get Field Mapping API . If running locally , request will not raise errors if running locally & amp ; missing indices . Returns the fields mapping . The return map keys are indexes and fields ( as specified in the request ) . Returns the mappings of a specific index and field . Returns the mappings as a map . pkg-private for testing This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation 0 system roles plus the three we created allow random fields at the level of ` index ` and ` index.mappings.field ` otherwise random field could be evaluated as index name or type name if mappings is empty , means that fields are not found As the client class GetFieldMappingsResponse does n't have toXContent method , adding this method here only for the test metadata is a series of kv pairs , so we dont want to add random fields here for test equality Request the mappings of specific fields Note : there is a new class with the same name for the Java HLRC that uses a typeless format . Any changes done to this class should go to that client class as well . Any changes done to this class should go to that client class as well . reserve \\'null\\ ' for bwc . The node-level ` discovery.zen.minimum_master_nodes ` setting on the master node that published this cluster state , for use in rolling upgrades from 6.x to 7.x . Once all the 6.x master-eligible nodes have left the cluster , the 7.x nodes use this value to determine how many master-eligible nodes must be discovered before the cluster can be bootstrapped . Note that this method returns the node-level value of this setting , and ignores any cluster-level override that was set via the API . Callers are expected to combine this value with any value set in the cluster-level settings . no Zen1 nodes found , but the last-known master was a Zen1 node , so this is a rolling upgrade It 's possible for replicaNodeVersion to be null , when disassociating dead nodes nothing to do until we actually recover from the gateway or any other block indicates we need to disable persistency Reads a list of strings . The consumer is only notified if at least one of the settings change . < /p > use a linked hash set to preserve order preserve insertion order This unassigns a task from any node , i.e . The ack timeout of 0 on dynamic mapping updates makes it possible for the document to be indexed on the primary , even if the dynamic mapping update is not applied on the replica yet . ... and wait for second mapping to be available on master Speed up rechecks to a rate that is quicker than what settings would allow Disallow re-assignment after it is unallocated to verify master and node state Verify that the task is NOT running on the node Verify that the task is STILL in internal cluster state Allow it to be reassigned again to the same node Verify it starts again Complete or cancel the running task Wait for the task to start ensures we do n't block Dynamic node setting for specifying the wait_for_timeout that the auto follow coordinator should be using . TODO : Deprecate and remove this setting must capture after snapshotting operations to ensure this MUS is at least the highest MUS of any of these operations . must capture IndexMetaData after snapshotting operations to ensure the returned mapping version is at least as up-to-date as the mapping version that these operations used . Here we must not use IndexMetaData from ClusterService for we expose a new cluster state to ClusterApplier ( s ) before exposing it in the ClusterService . if wait_for_metadata_version timeout , the response is empty ask for the next version . Pause follower1 index and check the follower info api : Block the ClusterService from exposing the cluster state with the mapping change . This makes the ClusterService have an older mapping version than the actual mapping version that IndexService will use to index \\'doc1\\ ' . Make sure at least one read-request which requires mapping sync is completed . This is an abstract AsyncActionStep that wraps the performed action listener , checking to see if the action fails due to a snapshot being in progress . If a snapshot is in progress , it registers an observer and waits to try again when a snapshot is no longer running . Wrap the original listener to handle exceptions caused by ongoing snapshots Method to be performed during which no snapshots for the index are already underway . The index has since been deleted , mission accomplished ! Re-invoke the performAction method with the new state TODO : what is a good timeout value for no new state received during this time ? If a snapshot is still running it registers a new listener and tries again . Passes any exceptions to the original exception listener if they occur . No snapshots are running , new state is acceptable to proceed There is a snapshot running with this index name There are snapshots , but none for this index , so it 's okay to proceed with this state This means the cluster is being shut down , so nothing to do here A utility class used for loading index lifecycle policies from the resource classpath Loads a built-in index lifecycle policy and returns its source . Create the repository before taking the snapshot . start snapshot add policy and expect it to trigger unfollow immediately ( while snapshot in progress ) Ensure that 'index.lifecycle.indexing_complete ' is replicated : ILM should have unfollowed the follower index , so the following_index setting should have been removed : ( this controls whether the follow engine is used ) Following index should have the document ILM should have completed the unfollow assert that snapshot succeeded Create the repository before taking the snapshot . create delete policy create index without policy index document so snapshot actually does something start snapshot add policy and expect it to trigger delete immediately ( while snapshot in progress ) assert that index was deleted assert that snapshot is still in progress and clean up Create the repository before taking the snapshot . create delete policy create index without policy required so the shrink does n't wait on SetSingleNodeAllocateStep index document so snapshot actually does something start snapshot add policy and expect it to trigger shrink immediately ( while snapshot in progress ) assert that index was shrunk and original index was deleted assert that snapshot succeeded Create the repository before taking the snapshot . create delete policy create index without policy index document so snapshot actually does something start snapshot add policy and expect it to trigger delete immediately ( while snapshot in progress ) assert that the index froze assert that snapshot is still in progress and clean up audit trail service construction .security index is not managed by using templates anymore the only available output type is \\'logfile\\ ' , but the optputs= < list > is to keep compatibility with previous reporting format When the histogram in SQL is applied on DATE type instead of DATETIME , the interval specified is truncated to the multiple of a day . If the interval specified is less than 0 day , then the interval used will be ` INTERVAL ' 0 ' DAY ` . For testing"
      }
    }
  },
  "elastic/elasticsearch_37767": {
    "id": "elastic/elasticsearch_37767",
    "body": "connectivity to the remote connection is failing .",
    "cms": [
      "'Fail with a dedicated exception if remote connection is missing or\\nconnectivity to the remote connection is failing.\\n\\nRelates to #37681'",
      "'Merge remote-tracking branch 'es/master' into dedicated_so_such_remote_cluster_exception'",
      "'extend from ResourceNotFoundException'"
    ],
    "commits": {
      "'369cca2c8c87aed2f2f60e39dcd432e64f5a17ef'": {
        "cm": "Fail with a dedicated exception if remote connection is missing or connectivity to the remote connection is failing .",
        "comments": "An exception that remote cluster is missing or connectivity to the remote connection is failing No node available for cluster ignore , this is an expected exception"
      },
      "'72f7189830e75abd3d15e917a0059bce51888ad6'": {
        "cm": "Merge remote-tracking branch 'es/master ' into dedicated_so_such_remote_cluster_exception",
        "comments": "we need to specify the exact version of build-tools because gradle automatically adds its plugin portal which appears to mirror jcenter , opening us up to pulling a \\'later\\ ' version of build-tools Retrieves the field mappings on an index or indices using the Get Field Mapping API . If running locally , request will not raise errors if running locally & amp ; missing indices . Returns the fields mapping . The return map keys are indexes and fields ( as specified in the request ) . Returns the mappings of a specific index and field . Returns the mappings as a map . pkg-private for testing This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation This is no longer true for all methods . Some methods can contain these 0 args backwards because of deprecation 0 system roles plus the three we created allow random fields at the level of ` index ` and ` index.mappings.field ` otherwise random field could be evaluated as index name or type name if mappings is empty , means that fields are not found As the client class GetFieldMappingsResponse does n't have toXContent method , adding this method here only for the test metadata is a series of kv pairs , so we dont want to add random fields here for test equality Request the mappings of specific fields Note : there is a new class with the same name for the Java HLRC that uses a typeless format . Any changes done to this class should go to that client class as well . Any changes done to this class should go to that client class as well . The node-level ` discovery.zen.minimum_master_nodes ` setting on the master node that published this cluster state , for use in rolling upgrades from 6.x to 7.x . Once all the 6.x master-eligible nodes have left the cluster , the 7.x nodes use this value to determine how many master-eligible nodes must be discovered before the cluster can be bootstrapped . Note that this method returns the node-level value of this setting , and ignores any cluster-level override that was set via the API . Callers are expected to combine this value with any value set in the cluster-level settings . no Zen1 nodes found , but the last-known master was a Zen1 node , so this is a rolling upgrade It 's possible for replicaNodeVersion to be null , when disassociating dead nodes Reads a list of strings . The consumer is only notified if at least one of the settings change . < /p > This unassigns a task from any node , i.e . The ack timeout of 0 on dynamic mapping updates makes it possible for the document to be indexed on the primary , even if the dynamic mapping update is not applied on the replica yet . ... and wait for second mapping to be available on master Speed up rechecks to a rate that is quicker than what settings would allow Disallow re-assignment after it is unallocated to verify master and node state Verify that the task is NOT running on the node Verify that the task is STILL in internal cluster state Allow it to be reassigned again to the same node Verify it starts again Complete or cancel the running task Wait for the task to start Dynamic node setting for specifying the wait_for_timeout that the auto follow coordinator should be using . TODO : Deprecate and remove this setting must capture after snapshotting operations to ensure this MUS is at least the highest MUS of any of these operations . must capture IndexMetaData after snapshotting operations to ensure the returned mapping version is at least as up-to-date as the mapping version that these operations used . Here we must not use IndexMetaData from ClusterService for we expose a new cluster state to ClusterApplier ( s ) before exposing it in the ClusterService . if wait_for_metadata_version timeout , the response is empty ask for the next version . Pause follower1 index and check the follower info api : Block the ClusterService from exposing the cluster state with the mapping change . This makes the ClusterService have an older mapping version than the actual mapping version that IndexService will use to index \\'doc1\\ ' . Make sure at least one read-request which requires mapping sync is completed . This is an abstract AsyncActionStep that wraps the performed action listener , checking to see if the action fails due to a snapshot being in progress . If a snapshot is in progress , it registers an observer and waits to try again when a snapshot is no longer running . Wrap the original listener to handle exceptions caused by ongoing snapshots Method to be performed during which no snapshots for the index are already underway . The index has since been deleted , mission accomplished ! Re-invoke the performAction method with the new state TODO : what is a good timeout value for no new state received during this time ? If a snapshot is still running it registers a new listener and tries again . Passes any exceptions to the original exception listener if they occur . No snapshots are running , new state is acceptable to proceed There is a snapshot running with this index name There are snapshots , but none for this index , so it 's okay to proceed with this state This means the cluster is being shut down , so nothing to do here A utility class used for loading index lifecycle policies from the resource classpath Loads a built-in index lifecycle policy and returns its source . Create the repository before taking the snapshot . start snapshot add policy and expect it to trigger unfollow immediately ( while snapshot in progress ) Ensure that 'index.lifecycle.indexing_complete ' is replicated : ILM should have unfollowed the follower index , so the following_index setting should have been removed : ( this controls whether the follow engine is used ) Following index should have the document ILM should have completed the unfollow assert that snapshot succeeded Create the repository before taking the snapshot . create delete policy create index without policy index document so snapshot actually does something start snapshot add policy and expect it to trigger delete immediately ( while snapshot in progress ) assert that index was deleted assert that snapshot is still in progress and clean up Create the repository before taking the snapshot . create delete policy create index without policy required so the shrink does n't wait on SetSingleNodeAllocateStep index document so snapshot actually does something start snapshot add policy and expect it to trigger shrink immediately ( while snapshot in progress ) assert that index was shrunk and original index was deleted assert that snapshot succeeded Create the repository before taking the snapshot . create delete policy create index without policy index document so snapshot actually does something start snapshot add policy and expect it to trigger delete immediately ( while snapshot in progress ) assert that the index froze assert that snapshot is still in progress and clean up audit trail service construction .security index is not managed by using templates anymore the only available output type is \\'logfile\\ ' , but the optputs= < list > is to keep compatibility with previous reporting format When the histogram in SQL is applied on DATE type instead of DATETIME , the interval specified is truncated to the multiple of a day . If the interval specified is less than 0 day , then the interval used will be ` INTERVAL ' 0 ' DAY ` . For testing since ODBC and JDBC interpret precision for Date as display size Creates an date for SQL DATE type from the millis since epoch . Parses the given string into a Date ( SQL DATE type ) using UTC as a default timezone . double check back and forth conversion double check back and forth conversion dates/datetimes and intervals Package visible for testing ILM is required for watcher template index settings"
      },
      "'d3d871e3f90cf3848a66bf018b45a8f4295900df'": {
        "cm": "extend from ResourceNotFoundException",
        "comments": ""
      }
    }
  }
}
